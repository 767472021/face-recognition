#!/usr/bin/env python3

####################
# gen_vec_start.py #
####################

import os
import sys
import shutil
import numpy as np

ROOT_DIR = os.path.abspath("../")
sys.path.append(ROOT_DIR)
from image_embedding.img_to_vec import img_to_vec
from image_embedding.storage import serialize
from load_data import load_cnn


def gen_vec_start(min_prob_filter):
    '''
    It is used when the program starts or restarts in GUI:
    All 128-d vectors and ML model pickle files will be deleted
    
    0. Loops all images in the dataset,
    1. Convert them to 128-d vectors,
    2. Save the serialized dictionary (image_paths, 128-d vectors)
         - for individual identity (path:  ../embeddings/data/individual/<identity>/embeddings.pickle)
         - for all                 (path:  ../embeddings/data/overall/embeddings.pickle)

    Arguments:
    1. min_prob_filter:     Probability threshold to filter weak detection by ResNet

    Returns:
    1. num_identity:        Number of unique identity in dataset
    '''

    print("#################################")
    print("#################################")
    print("#####    Initialization     #####") 
    print("#####    Reset all data     #####") 
    print("#################################")
    print("#################################\n")

    DATASET_PATH = "dataset"
    EMBEDDING_OUTPUT = "embeddings/data"
    FILE_NAME = "embeddings.pickle"
    INDIVIDUAL = "individual"
    OVERALL = "overall"

    SVM_PATH = "face_recognition_model/svm"
    KNN_PATH = "face_recognition_model/knn"
    RF_PATH = "face_recognition_model/rf"

    # NOTE: This part is unique in this function
    #       It clears up all the pickle files
    #
    # Delete all pickle files that store 128-d vectors of each identity
    individual_path = os.path.join(EMBEDDING_OUTPUT, INDIVIDUAL)
    if os.path.isdir(individual_path):
        print("Delete all 128-d vectors for each identity")
        shutil.rmtree(individual_path)
    os.makedirs(individual_path)

    # Delete the pickle file that stores 128-d vectors of all identites
    # in embeddings/data/overall/embeddings.pickle
    overall_path = os.path.join(EMBEDDING_OUTPUT, OVERALL, FILE_NAME)
    if os.path.isfile(overall_path):
        print("Delete 128-d vectors in overall directory")
        os.remove(overall_path)
   
    # Delete all pickle files generated by SVM
    if os.path.isdir(SVM_PATH):
        print("Delete Support Vector Machine Model")
        shutil.rmtree(SVM_PATH)
    os.makedirs(SVM_PATH)

    # Delete all pickle files generated by KNN
    if os.path.isdir(KNN_PATH):
        print("Delete k-Nearest Neighbours Model")
        shutil.rmtree(KNN_PATH)
    os.makedirs(KNN_PATH)

    # Delete all pickle files generated by Random Forest
    if os.path.isdir(RF_PATH):
        print("Delete Random Forest Model")
        shutil.rmtree(RF_PATH)
    os.makedirs(RF_PATH)



    # Load the CNN for face detection and 128-d vector extraction
    detector = load_cnn.resnet()
    embedder = load_cnn.facenet()

    # Initialize list to store image path and 128-d vector
    # for ALL identities
    overall_image_paths = []
    overall_vectors = []

    # Total number of vectors for all identities
    vector_num_all = 0

    # Total number of image processed
    image_num_all = 0
    
    # Get all unique identities
    identities = [x for x in os.listdir(DATASET_PATH) if not x.startswith('.')]
    identities = sorted(identities)
    num_identity = len(identities)

    # Loop over all identities
    for identity in identities:
        print("\n*** Processing images with identity: " + identity + " ***")
        
        # Create directory for THIS identity to store 128-d vector
        vector_path = os.path.join(individual_path, identity)
        if not os.path.isdir(vector_path):
            os.makedirs(vector_path)
        else:
            print("WARNING: The path " + vector_path + " exists")
            print("         Removing all its contents")
            shutil.rmtree(vector_path)
            os.makedirs(vector_path)


        # Initialize list to store image path and 128-d vector
        # for THIS identity
        individual_image_paths = []
        individual_vectors = []

        # Total number of vector for THIS identity
        vector_num = 0

        # Setting up image path
        identity_path = os.path.join(DATASET_PATH, identity)
        image_files = [x for x in os.listdir(identity_path) if not x.startswith('.')]
        image_num = len(image_files)
        image_num_all += image_num


        # Loop over images for THIS identity
        for image_file in image_files: 
            image_path = os.path.join(identity_path, image_file)

            # Extract 128-d vector from the image
            vector = img_to_vec(image_path, detector, embedder, min_prob_filter)

            # Skip below if vector is not extracted
            if np.isfinite(vector).all() == False:
                print("WARNING: No 128-d vector extracted for " + image_path)
                continue                

            # For individual member
            individual_image_paths.append(image_path)
            individual_vectors.append(vector)

            # For overall
            overall_image_paths.append(image_path)
            overall_vectors.append(vector)

            vector_num += 1
            vector_num_all +=1

        # Save the extracted 128-d vectors for THIS identity
        print("Serializing {} 128-d vectors for {} images".format(vector_num, image_num))
        output_path = os.path.join(EMBEDDING_OUTPUT, INDIVIDUAL, identity, FILE_NAME)
        data = dict(zip(individual_image_paths, individual_vectors))
        serialize(data, output_path)

        print("*** Done with identity: " + identity + " ***\n")

    # Save the extracted 128-d vectors for ALL identities
    print("****** Combining All vectors ******")
    print("Serializing {} 128-d vectors for {} images".format(vector_num_all, image_num_all))
    output_path = os.path.join(EMBEDDING_OUTPUT, OVERALL, FILE_NAME)
    data = dict(zip(overall_image_paths, overall_vectors))
    serialize(data, output_path)
    print("****** Initialization completed!!! ******")

    return num_identity

